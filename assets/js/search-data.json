{
  
    
        "post0": {
            "title": "Data Analysis   Report",
            "content": "Trends over time in male and female employment . The sector currently employs approximately two times more females than males and the ratio of males has been declining over the last five years as evident in Figure 1. . [CHART] . Figure 1 Male vs female ratio. . Another observation is that after 2014 the number of both females and males dropped and this continued until 2017 when the number of females employed by the sector grew more than 2014, but the number of males has not recovered yet as can be seen in Figure 2. . [CHART] . Figure 2 Headcount difference to 2014 by gender. . The current representation of part time employees in the sector and in each Cluster . The sector employs 112,250 part-time employees which is 29.58% of the headcount. The highest ratio of part-time to total headcount per cluster is in Education which is 44.20% while the lowest is in the industry at 6.66% as evident in Figure 3. Health and Education combined employ ~85% of the whole part-time headcount as can be seen in Figure 4. . [CHART] . Figure 3 Part-time representation per cluster. . [CHART] . Figure 4 Part-time distribution on clusters . The current representation of male and female part time employees as a proportion of the respective male and the female workforce in the sector and in each cluster . 36.67% of the females and 16.52% of the males employed by the sector are on part-time basis. Education is largest employer of part-time for both males and females followed by Health for females and Family and Community Services for males. The least employer of part-time employees is Treasury for both, males, and females as evident in Figure 5. . [CHART] . Figure 5 Part-time to total headcount ratio by gender . Change in part-time statistics over the last 4 years . A summary of the trends in the number of male and female employees on part-time basis is in Table 1. . ¬† Female Male ¬† ¬† ¬† ¬† . Cluster | 2014 | 2018 | Trend | 2014 | 2018 | Trend | . Education | 45.9% | 46.8% | Increasing | 20.1% | 35.3% | Increasing | . Family &amp; Community Services | 36.9% | 16.9% | Decreasing | 21.4% | 4.7% | Decreasing | . Finance, Services &amp; Innovation | 15.4% | 27.0% | Increasing | 2.9% | 20.0% | Increasing | . Health | 36.2% | 37.7% | Increasing | 15.2% | 19.9% | Increasing | . Industry | 18.0% | 10.9% | Decreasing | 5.1% | 2.0% | Decreasing | . Justice | 20.2% | 18.8% | Decreasing | 1.5% | 5.1% | Increasing | . Planning &amp; Environment | 25.4% | 24.7% | Decreasing | 5.2% | 5.1% | Increasing | . Premier &amp; Cabinet | 18.3% | 17.4% | Decreasing | 7.7% | 6.3% | Decreasing | . Transport | 25.3% | 18.2% | Decreasing | 5.2% | 13.0% | Increasing | . Treasury | 7.6% | 14.2% | Increasing | 2.4% | 3.0% | Increasing | . Table 1 Trends in part-time employment per cluster . Projection of what the representation will be by 2025 if the current trends continue . If the current trend continued: . the percentage of part-time females will be increase from the current 36.7% to 37.6% in 2025, . | the percentage of part-time males will increase from the current 16.5% to become 26.8%, . | the ratio of part-time to the total employees will increase from 29.6% to 34.2%. . | . These trends can be seen in Figure 6. . [CHART][CHART] . [CHART] . Figure 6 Projections for 2025 .",
            "url": "https://waseemwaheed.github.io/DataInterrogator/2021/08/17/Data-Analysis-Report.html",
            "relUrl": "/2021/08/17/Data-Analysis-Report.html",
            "date": " ‚Ä¢ Aug 17, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "A solution to a coding challenge",
            "content": "Introduction . I have recently been invited to a coding challenge which was required to be delivered in 7 days. The task was very simple üòé: . Coding challenge . The aim of this exercise is to implement an ‚Äúalerting‚Äù service which will consume a file of currency conversion rates and produce alerts. . For the purpose of this coding exercise, you are allowed to choose a different programming language, provided that you provide us with a detailed instruction on how to build and run your program. . Input . The format of the file will simulate a stream of currency conversion rates. Each line will be properly structured JSON (http://jsonlines.org/): . { ‚Äútimestamp‚Äù: 1554933784.023, ‚ÄúcurrencyPair‚Äù: ‚ÄúCNYAUD‚Äù, ‚Äúrate‚Äù: 0.39281 } . The fields in the JSON record are: . timestamp: the timestamp of the record in seconds since UNIX epoch, with fractional seconds specified | currencyPair: the sell and buy currencies which the rate relates to | rate: the conversion rate | . You may assume that for each currency pair, currency conversion rates are streamed at a constant rate of one per second. ie. for two consecutive ‚ÄúCNYAUD‚Äù entries in in the input file, they will have timestamps that differ by one second: . { &quot;timestamp&quot;: 1554933784.023, &quot;currencyPair&quot;: &quot;CNYAUD&quot;, &quot;rate&quot;: 0.39281 } { &quot;timestamp&quot;: 1554933784.087, &quot;currencyPair&quot;: &quot;USDAUD&quot;, &quot;rate&quot;: 0.85641 } { &quot;timestamp&quot;: 1554933785.023, &quot;currencyPair&quot;: &quot;CNYAUD&quot;, &quot;rate&quot;: 0.39295 } . Output . The alerting service should produce the following alert as a JSON string output to standard output: . when the spot rate for a currency pair changes by more than 10% from the 5 minute average for that currency pair | . The format of the alert produced should be: . { ‚Äútimestamp‚Äù: 1554933784.023, ‚ÄúcurrencyPair‚Äù: ‚ÄúCNYAUD‚Äù, ‚Äúalert‚Äù: ‚ÄúspotChange‚Äù } . As mentioned earlier, the task is very simple but I wanted to take the opportunity to improve the following aspects: . Code readability | Unit testing | Deployability | . Code readability . I use VSCODE for many tasks, and it is my main text editor so naturally, I looked for tools that play well with it. For automatic code styling, I used black which is a great code formatter. Additionally, I revised the PEP 8 guide to refresh my memory of best practices. . Unit Testing . The idea behind unit testing is that you have to arrange your code into non-coupled components to allow for testing. In the Python ecosystem there are few options such as the unittest which comes as part of the Python Standard Library and pytest. I ended up using pytest because I wanted to learn it. . Deployability . Python, similar to other interpreted languages, requires a compatible version of the interpreter and the same version of packages (excluding Javascript, where every computer nowadays comes with one). This is a common issue that has many solutions. Among those solutions are the virtual environments such as (venv, virtualenv, conda env) and containers such as the well-known docker. . The simplicity and ubiquity of docker made it a simple choice üëç for me in this challenge. Once the code is written and tested, docker image description file is all that is needed. The alternative path of virtual environment was also a viable one, I just had to write enviroment creation scripts, one for windows and one for Unix/Linux ü•±. . My solution . You can access the solution over here . . Assumptions . One input file can be consumed at a time. | The frequency at which updates arrive is fixed (1s). Hence the average, in the general case, is taken over 300 samples. | A single stream (input file) can contain more than one currency pair. | . Decisions . To keep track of the exchange rates for each pair, I made the currency pairs keys of a dictionary which maps to sliding window deque data structure. The rationale behind choosing a dictionary is because, each new line can be new data point for a currency pair, which means the currency pairs data need to be accessed in random order and a dictionary is the best options here where an access operation is $O(1)$ | The rationale behind choosing a deque is that it allows for the easy creation of a sliding window. A deque has $O(1)$ complexity when we append to or access the ends of the queue, which is what we are doing here. | . | The CurrencyPairData class is a subclass of the Observable class. This allows me to easily add callbacks to CurrencyPairData instances. | . In the end . The coding challenge was a fun opportunity to build something and get someone to give me feedback on my approach. Additionally, I had a ton of fun learning about pytest and docker which will definitely be used in my other projects. .",
            "url": "https://waseemwaheed.github.io/DataInterrogator/python/docker/unit%20testing/software%20engineering/data%20structures/json/2021/08/13/Coding-Challenge-Solution.html",
            "relUrl": "/python/docker/unit%20testing/software%20engineering/data%20structures/json/2021/08/13/Coding-Challenge-Solution.html",
            "date": " ‚Ä¢ Aug 13, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Making the TITAN GTX GPU available to Tensorflow",
            "content": "Introduction . This post is to document üìù a process I had to go through. Installing Tensorflow on Ubuntu. . To make use of the GPU(s) in Tensorflow, Linux should be able to detect the GPU and tensorflow-gpu should be installed. . The process . First of all, you need to check that Linux can detect the GPU as follows: you can either do: . user# sudo lshw -C display . or: . user# nvidia-smi . which should show you a list containing all the NVIDIA GPUs attached to your machine. . Next, to check if tensorflow-gpu is installed, we can use the following command . user# pip list | grep tensor tensorboard 2.4.1 tensorboard-plugin-wit 1.8.0 tensorflow 1.14.0 tensorflow-estimator 2.3.0 . as we can see, tensorflow-gpu is not in the list. To install it, we use: . user# sudo pip install --upgrade pip user# pip install tensorflow-gpu --user . once finished, we should check the correct operation of Tensorflow as follows: . user# python . import tensorflow as tf print(tf.config.experimental.list_physical_devices(&#39;GPU&#39;)) . which should give you a list of the installed GPUs. To use a specific GPU within a context: . tf.debugging.set_log_device_placement(True) try: # Specify an invalid GPU device with tf.device(&#39;/device:GPU:1&#39;): a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]) b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]) c = tf.matmul(a, b) except RuntimeError as e: print(e) . To use a specific GPU for all Tensorflow‚Äôs calculations, use the following template: . import tensorflow as tf gpus = tf.config.experimental.list_physical_devices(&#39;GPU&#39;) if gpus: # Restrict TensorFlow to only use the first GPU try: tf.config.experimental.set_visible_devices(gpus[0], &#39;GPU&#39;) logical_gpus = tf.config.experimental.list_logical_devices(&#39;GPU&#39;) print(len(gpus), &quot;Physical GPUs,&quot;, len(logical_gpus), &quot;Logical GPU&quot;) except RuntimeError as e: # Visible devices must be set before GPUs have been initialized print(e) . Note: this note took advantage of Tensorflow‚Äôs documentation @ https://www.tensorflow.org/guide/gpu . In the end . I hope that this write up has helped you installing from scratch/fixing your Tensorflow installation. .",
            "url": "https://waseemwaheed.github.io/DataInterrogator/python/linux/tensorflow/software%20engineering/2020/11/15/Making-TITAN-GTX-GPU-available-to-Tensorflow.html",
            "relUrl": "/python/linux/tensorflow/software%20engineering/2020/11/15/Making-TITAN-GTX-GPU-available-to-Tensorflow.html",
            "date": " ‚Ä¢ Nov 15, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Benford's Law",
            "content": "Benford‚Äôs law . Few days ago, I was introduced to the Benford‚Äôs law of distribution. Looking up the internet for accessible explanation, I came across a basic introduction with very interesting explanation on Khan Academy. Sal mentioned the typical example of the world countries populations follow this fascinating distribution function. . After few seconds of thinking about it, I decided to confirm this claim, So, I quickly pulled the data from wikipedia and coded a quick and dirty experiment. And sure it works as you can see bellow . . Code and data can be found in my GitHub .",
            "url": "https://waseemwaheed.github.io/DataInterrogator/analysis/probability/2017/07/07/benfords-law.html",
            "relUrl": "/analysis/probability/2017/07/07/benfords-law.html",
            "date": " ‚Ä¢ Jul 7, 2017"
        }
        
    
  
    
        ,"post4": {
            "title": "D3 - visualizing temperature 2",
            "content": "Today‚Äôs post is a bit delayed, anyway, I went through the same data from day 1 (temperature measurements) but this time I, used leaflet.js instead of google maps API starting from from the example. The beautiful thing about leaflet is that it doesn‚Äôt abstract the whole DOM event-handling like in google maps which means events set using d3 are handled normally. . I have manged to encoded the data in color, size and in text in the form of tool-tips. . . The code can be found at here .",
            "url": "https://waseemwaheed.github.io/DataInterrogator/d3/visualization/2017/07/03/D3js-Explorations-4.html",
            "relUrl": "/d3/visualization/2017/07/03/D3js-Explorations-4.html",
            "date": " ‚Ä¢ Jul 3, 2017"
        }
        
    
  
    
        ,"post5": {
            "title": "D3 - visualizing connections",
            "content": "Today work is my own go at arc diagrams replicating a worked example at Matthew Clemens‚Äôs blog post. My code can be found at Github . .",
            "url": "https://waseemwaheed.github.io/DataInterrogator/d3/visualization/2017/07/01/D3js-Explorations-3.html",
            "relUrl": "/d3/visualization/2017/07/01/D3js-Explorations-3.html",
            "date": " ‚Ä¢ Jul 1, 2017"
        }
        
    
  
    
        ,"post6": {
            "title": "D3 - Visualizing bike share stations on map",
            "content": "I started today with a goal to plot data from Melbourne city particularly Melbourne Bike Share stations on google maps with marker size and color representing the size of the station and the availability of bikes respectively in addition to tooltips containing the details of each station on hover. . Mapping the data went smoothly but tooltips turned to be tricky, it took me some time to decide to postpone it to another stage. I think the problem has to do with google maps handling events not D3 so in other words events are not being passed to D3. Handling events with google maps is straight forward but finding the current location of the markers to compare with the current mouse position is not clear at this point. . Anyway, I think the visualization is still interesting. . .",
            "url": "https://waseemwaheed.github.io/DataInterrogator/d3/visualization/2017/06/30/d3js-Explorations-2.html",
            "relUrl": "/d3/visualization/2017/06/30/d3js-Explorations-2.html",
            "date": " ‚Ä¢ Jun 30, 2017"
        }
        
    
  
    
        ,"post7": {
            "title": "D3 - Visualizing temperature 1",
            "content": "This is the first day of the challenge but I have been tinkering with D3 for few days now. . My first day started with an intention to project points on a map so, I had a look at few examples by they seemed complicated so I adjusted my aims from drawing the map with d3 to mapping the data with d3 and get the map from a map provider (google maps or leaflet). I started with an example by Mike Bostock which is very accessible and I adapted it. My data that I had which is the locations of temperature sensors spread across the US (source : GSOD) as well as summary temperature measurement for one day. I‚Äôm happy with the result for today as I managed to project the sensors on the map and color coded the points based on temperature measurement. . My adapted version of the code can be found on my github . . Future directions : . Draw connections between nodes | include a slider to select the day of the year. |",
            "url": "https://waseemwaheed.github.io/DataInterrogator/d3/visualization/2017/06/29/D3js-Explorations-1.html",
            "relUrl": "/d3/visualization/2017/06/29/D3js-Explorations-1.html",
            "date": " ‚Ä¢ Jun 29, 2017"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi this is me . My main skills are: . Software engineering (Python, Java, C) | Predictive analytics (R, Python) | Data analysis (SQL, R, Python, Excel) | Data visualization (PowerBI, matplotlib, seaborn, ggplot) | Technical writing | . I have a PhD in Image processing, and my main research area is continuous optimization techniques in signal and image processing. . My thesis is at the intersection of: . Optimization | Signal processing | Image processing | Graph theory | I currently work as a sessional lecturer in the computer science department at both La Trobe University and Charles Sturt Univesity. The subjects I teach include: Natural Language Processing, Internet Of Things, Wireless Communications/Networking. . In 2018, I spent 5 months at Aurecon working on three data science projects in the area of asset management, mainly developing image processing/computer vision and machine learning solutions targeted at streamlining asset management processes. . I am broadly interested in data science, computer vision, natural language processing, computer programming, computer networking and IT in general. .",
          "url": "https://waseemwaheed.github.io/DataInterrogator/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://waseemwaheed.github.io/DataInterrogator/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}