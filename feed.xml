<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://datainterrogator.org/feed.xml" rel="self" type="application/atom+xml" /><link href="https://datainterrogator.org/" rel="alternate" type="text/html" /><updated>2022-02-27T17:17:59-06:00</updated><id>https://datainterrogator.org/feed.xml</id><title type="html">Data Interrogator</title><subtitle>A personal blog about software engineering and data science</subtitle><entry><title type="html">ML challenge - Part 1</title><link href="https://datainterrogator.org/2022/01/10/ML-Challenge-part-1.html" rel="alternate" type="text/html" title="ML challenge - Part 1" /><published>2022-01-10T00:00:00-06:00</published><updated>2022-01-10T00:00:00-06:00</updated><id>https://datainterrogator.org/2022/01/10/ML-Challenge-part-1</id><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Learning Analytics - Dashboard with Google Data Studio</title><link href="https://datainterrogator.org/dashboard/analytics/2021/09/04/Learning-Analytics-Dashboard-with-Google-Data-Studio.html" rel="alternate" type="text/html" title="Learning Analytics - Dashboard with Google Data Studio" /><published>2021-09-04T00:00:00-05:00</published><updated>2021-09-04T00:00:00-05:00</updated><id>https://datainterrogator.org/dashboard/analytics/2021/09/04/Learning-Analytics-Dashboard-with-Google-Data-Studio</id><author><name></name></author><category term="Dashboard" /><category term="Analytics" /><summary type="html">COVID-19 has had a significant impact on our lives as a whole. Most industries have suffered from unexpected shift in customers demand. Few industries however have emerged unscathed from this pandemic, including retail, technology and health. Education has been on the industries hit very hard, and the result of this impact is yet to be fully understood. This could well be the beginning of an unprecedented transformation across the sector. LearnPlatform is a US based company that is specialized in EdTech, their mission is Expand equitable access for all students to teaching and education technology that works best for them. Source The company has a browser extension that collects data about usage of EdTech tools. They have recently announced a competition of Kaggle aimed at better understanding and measuring the scope and impact of the pandemic on inequities in the system. The hypothesis is that the pandemic has increased those inequities which is a sad but reasonable hypothesis. The role of data analytics is to uncover the hidden realities in the data. That is not to say that the provided data set allows us to make any conclusion at this stageü§î. I have made an initial attempt to familiarize myself with the data by building a little and crude dashboard which can be accessed here. This dashboard gave me few questions to start exploring, so this is not the end (hopefullyü§û).</summary></entry><entry><title type="html">Efficient Data Analysis - SQL and Python</title><link href="https://datainterrogator.org/2021/08/28/Efficient-Data-Analysis-SQL-and-Python.html" rel="alternate" type="text/html" title="Efficient Data Analysis - SQL and Python" /><published>2021-08-28T00:00:00-05:00</published><updated>2021-08-28T00:00:00-05:00</updated><id>https://datainterrogator.org/2021/08/28/Efficient-Data-Analysis-SQL-and-Python</id><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">A solution to a coding challenge</title><link href="https://datainterrogator.org/python/docker/unit%20testing/software%20engineering/data%20structures/json/2021/08/13/Coding-Challenge-Solution.html" rel="alternate" type="text/html" title="A solution to a coding challenge" /><published>2021-08-13T00:00:00-05:00</published><updated>2021-08-13T00:00:00-05:00</updated><id>https://datainterrogator.org/python/docker/unit%20testing/software%20engineering/data%20structures/json/2021/08/13/Coding-Challenge-Solution</id><author><name></name></author><category term="Python" /><category term="Docker" /><category term="Unit Testing" /><category term="Software Engineering" /><category term="Data Structures" /><category term="JSON" /><summary type="html">Introduction I have recently been invited to a coding challenge which was required to be delivered in 7 days. The task was very simple üòé: Coding challenge The aim of this exercise is to implement an ‚Äúalerting‚Äù service which will consume a file of currency conversion rates and produce alerts. For the purpose of this coding exercise, you are allowed to choose a different programming language, provided that you provide us with a detailed instruction on how to build and run your program. Input The format of the file will simulate a stream of currency conversion rates. Each line will be properly structured JSON (http://jsonlines.org/): { ‚Äútimestamp‚Äù: 1554933784.023, ‚ÄúcurrencyPair‚Äù: ‚ÄúCNYAUD‚Äù, ‚Äúrate‚Äù: 0.39281 } The fields in the JSON record are: timestamp: the timestamp of the record in seconds since UNIX epoch, with fractional seconds specified currencyPair: the sell and buy currencies which the rate relates to rate: the conversion rate You may assume that for each currency pair, currency conversion rates are streamed at a constant rate of one per second. ie. for two consecutive ‚ÄúCNYAUD‚Äù entries in in the input file, they will have timestamps that differ by one second: { &quot;timestamp&quot;: 1554933784.023, &quot;currencyPair&quot;: &quot;CNYAUD&quot;, &quot;rate&quot;: 0.39281 } { &quot;timestamp&quot;: 1554933784.087, &quot;currencyPair&quot;: &quot;USDAUD&quot;, &quot;rate&quot;: 0.85641 } { &quot;timestamp&quot;: 1554933785.023, &quot;currencyPair&quot;: &quot;CNYAUD&quot;, &quot;rate&quot;: 0.39295 } Output The alerting service should produce the following alert as a JSON string output to standard output: when the spot rate for a currency pair changes by more than 10% from the 5 minute average for that currency pair The format of the alert produced should be: { ‚Äútimestamp‚Äù: 1554933784.023, ‚ÄúcurrencyPair‚Äù: ‚ÄúCNYAUD‚Äù, ‚Äúalert‚Äù: ‚ÄúspotChange‚Äù } As mentioned earlier, the task is very simple but I wanted to take the opportunity to improve the following aspects: Code readability Unit testing Deployability Code readability I use VSCODE for many tasks, and it is my main text editor so naturally, I looked for tools that play well with it. For automatic code styling, I used black which is a great code formatter. Additionally, I revised the PEP 8 guide to refresh my memory of best practices. Unit Testing The idea behind unit testing is that you have to arrange your code into non-coupled components to allow for testing. In the Python ecosystem there are few options such as the unittest which comes as part of the Python Standard Library and pytest. I ended up using pytest because I wanted to learn it. Deployability Python, similar to other interpreted languages, requires a compatible version of the interpreter and the same version of packages (excluding Javascript, where every computer nowadays comes with one). This is a common issue that has many solutions. Among those solutions are the virtual nments such as (venv, virtualenv, conda env) and containers such as the well-known docker. The simplicity and ubiquity of docker made it a simple choice üëç for me in this challenge. Once the code is written and tested, docker image description file is all that is needed. The alternative path of virtual environment was also a viable one, I just had to write environment creation scripts, one for windows and one for Unix/Linux ü•±. My solution You can access the solution over here . Assumptions One input file can be consumed at a time. The frequency at which updates arrive is fixed (1s). Hence the average, in the general case, is taken over 300 samples. A single stream (input file) can contain more than one currency pair. Decisions To keep track of the exchange rates for each pair, I made the currency pairs keys of a dictionary which maps to sliding window deque data structure. The rationale behind choosing a dictionary is because, each new line can be new data point for a currency pair, which means the currency pairs data need to be accessed in random order and a dictionary is the best options here where an access operation is $O(1)$ The rationale behind choosing a deque is that it allows for the easy creation of a sliding window. A deque has $O(1)$ complexity when we append to or access the ends of the queue, which is what we are doing here. The CurrencyPairData class is a subclass of the Observable class. This allows me to easily add callbacks to CurrencyPairData instances. In the end The coding challenge was a fun opportunity to build something and get someone to give me feedback on my approach. Additionally, I had a ton of fun learning about pytest and docker which will definitely be used in my other projects.</summary></entry><entry><title type="html">Making the TITAN GTX GPU available to Tensorflow</title><link href="https://datainterrogator.org/python/linux/tensorflow/software%20engineering/2020/11/15/Making-TITAN-GTX-GPU-available-to-Tensorflow.html" rel="alternate" type="text/html" title="Making the TITAN GTX GPU available to Tensorflow" /><published>2020-11-15T00:00:00-06:00</published><updated>2020-11-15T00:00:00-06:00</updated><id>https://datainterrogator.org/python/linux/tensorflow/software%20engineering/2020/11/15/Making-TITAN-GTX-GPU-available-to-Tensorflow</id><author><name></name></author><category term="Python" /><category term="Linux" /><category term="Tensorflow" /><category term="Software Engineering" /><summary type="html">Introduction</summary></entry></feed>