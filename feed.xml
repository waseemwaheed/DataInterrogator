<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://waseemwaheed.github.io/DataInvestig8or/feed.xml" rel="self" type="application/atom+xml" /><link href="https://waseemwaheed.github.io/DataInvestig8or/" rel="alternate" type="text/html" /><updated>2021-08-17T10:28:07-05:00</updated><id>https://waseemwaheed.github.io/DataInvestig8or/feed.xml</id><title type="html">Data Interrogator</title><subtitle>A personal blog about software engineering and data science</subtitle><entry><title type="html">A solution to a coding challenge</title><link href="https://waseemwaheed.github.io/DataInvestig8or/python/docker/unit%20testing/software%20engineering/data%20structures/json/2021/08/13/Coding-Challenge-Solution.html" rel="alternate" type="text/html" title="A solution to a coding challenge" /><published>2021-08-13T00:00:00-05:00</published><updated>2021-08-13T00:00:00-05:00</updated><id>https://waseemwaheed.github.io/DataInvestig8or/python/docker/unit%20testing/software%20engineering/data%20structures/json/2021/08/13/Coding-Challenge-Solution</id><author><name></name></author><category term="Python" /><category term="Docker" /><category term="Unit Testing" /><category term="Software Engineering" /><category term="Data Structures" /><category term="JSON" /><summary type="html">Introduction I have recently been invited to a coding challenge which was required to be delivered in 7 days. The task was very simple üòé: Coding challenge The aim of this exercise is to implement an ‚Äúalerting‚Äù service which will consume a file of currency conversion rates and produce alerts. For the purpose of this coding exercise, you are allowed to choose a different programming language, provided that you provide us with a detailed instruction on how to build and run your program. Input The format of the file will simulate a stream of currency conversion rates. Each line will be properly structured JSON (http://jsonlines.org/): { ‚Äútimestamp‚Äù: 1554933784.023, ‚ÄúcurrencyPair‚Äù: ‚ÄúCNYAUD‚Äù, ‚Äúrate‚Äù: 0.39281 } The fields in the JSON record are: timestamp: the timestamp of the record in seconds since UNIX epoch, with fractional seconds specified currencyPair: the sell and buy currencies which the rate relates to rate: the conversion rate You may assume that for each currency pair, currency conversion rates are streamed at a constant rate of one per second. ie. for two consecutive ‚ÄúCNYAUD‚Äù entries in in the input file, they will have timestamps that differ by one second: { &quot;timestamp&quot;: 1554933784.023, &quot;currencyPair&quot;: &quot;CNYAUD&quot;, &quot;rate&quot;: 0.39281 } { &quot;timestamp&quot;: 1554933784.087, &quot;currencyPair&quot;: &quot;USDAUD&quot;, &quot;rate&quot;: 0.85641 } { &quot;timestamp&quot;: 1554933785.023, &quot;currencyPair&quot;: &quot;CNYAUD&quot;, &quot;rate&quot;: 0.39295 } Output The alerting service should produce the following alert as a JSON string output to standard output: when the spot rate for a currency pair changes by more than 10% from the 5 minute average for that currency pair The format of the alert produced should be: { ‚Äútimestamp‚Äù: 1554933784.023, ‚ÄúcurrencyPair‚Äù: ‚ÄúCNYAUD‚Äù, ‚Äúalert‚Äù: ‚ÄúspotChange‚Äù } As mentioned earlier, the task is very simple but I wanted to take the opportunity to improve the following aspects: Code readability Unit testing Deployability Code readability I use VSCODE for many tasks, and it is my main text editor so naturally, I looked for tools that play well with it. For automatic code styling, I used black which is a great code formatter. Additionally, I revised the PEP 8 guide to refresh my memory of best practices. Unit Testing The idea behind unit testing is that you have to arrange your code into non-coupled components to allow for testing. In the Python ecosystem there are few options such as the unittest which comes as part of the Python Standard Library and pytest. I ended up using pytest because I wanted to learn it. Deployability Python, similar to other interpreted languages, requires a compatible version of the interpreter and the same version of packages (excluding Javascript, where every computer nowadays comes with one). This is a common issue that has many solutions. Among those solutions are the virtual environments such as (venv, virtualenv, conda env) and containers such as the well-known docker. The simplicity and ubiquity of docker made it a simple choice üëç for me in this challenge. Once the code is written and tested, docker image description file is all that is needed. The alternative path of virtual environment was also a viable one, I just had to write enviroment creation scripts, one for windows and one for Unix/Linux ü•±. My solution You can access the solution over here . Assumptions One input file can be consumed at a time. The frequency at which updates arrive is fixed (1s). Hence the average, in the general case, is taken over 300 samples. A single stream (input file) can contain more than one currency pair. Decisions To keep track of the exchange rates for each pair, I made the currency pairs keys of a dictionary which maps to sliding window deque data structure. The rationale behind choosing a dictionary is because, each new line can be new data point for a currency pair, which means the currency pairs data need to be accessed in random order and a dictionary is the best options here where an access operation is $O(1)$ The rationale behind choosing a deque is that it allows for the easy creation of a sliding window. A deque has $O(1)$ complexity when we append to or access the ends of the queue, which is what we are doing here. The CurrencyPairData class is a subclass of the Observable class. This allows me to easily add callbacks to CurrencyPairData instances. In the end The coding challenge was a fun opportunity to build something and get someone to give me feedback on my approach. Additionally, I had a ton of fun learning about pytest and docker which will definitely be used in my other projects.</summary></entry><entry><title type="html">Making the TITAN GTX GPU available to Tensorflow</title><link href="https://waseemwaheed.github.io/DataInvestig8or/python/linux/tensorflow/software%20engineering/2020/11/15/Making-TITAN-GTX-GPU-available-to-Tensorflow.html" rel="alternate" type="text/html" title="Making the TITAN GTX GPU available to Tensorflow" /><published>2020-11-15T00:00:00-06:00</published><updated>2020-11-15T00:00:00-06:00</updated><id>https://waseemwaheed.github.io/DataInvestig8or/python/linux/tensorflow/software%20engineering/2020/11/15/Making-TITAN-GTX-GPU-available-to-Tensorflow</id><author><name></name></author><category term="Python" /><category term="Linux" /><category term="Tensorflow" /><category term="Software Engineering" /><summary type="html">Introduction</summary></entry><entry><title type="html">Benford‚Äôs Law</title><link href="https://waseemwaheed.github.io/DataInvestig8or/analysis/probability/2017/07/07/benfords-law.html" rel="alternate" type="text/html" title="Benford‚Äôs Law" /><published>2017-07-07T00:00:00-05:00</published><updated>2017-07-07T00:00:00-05:00</updated><id>https://waseemwaheed.github.io/DataInvestig8or/analysis/probability/2017/07/07/benfords-law</id><author><name></name></author><category term="Analysis" /><category term="Probability" /><summary type="html">Benford‚Äôs law Few days ago, I was introduced to the Benford‚Äôs law of distribution. Looking up the internet for accessible explanation, I came across a basic introduction with very interesting explanation on Khan Academy. Sal mentioned the typical example of the world countries populations follow this fascinating distribution function.</summary></entry><entry><title type="html">D3 - visualizing temperature 2</title><link href="https://waseemwaheed.github.io/DataInvestig8or/d3/visualization/2017/07/03/D3js-Explorations-4.html" rel="alternate" type="text/html" title="D3 - visualizing temperature 2" /><published>2017-07-03T00:00:00-05:00</published><updated>2017-07-03T00:00:00-05:00</updated><id>https://waseemwaheed.github.io/DataInvestig8or/d3/visualization/2017/07/03/D3js-Explorations-4</id><author><name></name></author><category term="D3" /><category term="Visualization" /><summary type="html">Today‚Äôs post is a bit delayed, anyway, I went through the same data from day 1 (temperature measurements) but this time I, used leaflet.js instead of google maps API starting from from the example. The beautiful thing about leaflet is that it doesn‚Äôt abstract the whole DOM event-handling like in google maps which means events set using d3 are handled normally.</summary></entry><entry><title type="html">D3 - visualizing connections</title><link href="https://waseemwaheed.github.io/DataInvestig8or/d3/visualization/2017/07/01/D3js-Explorations-3.html" rel="alternate" type="text/html" title="D3 - visualizing connections" /><published>2017-07-01T00:00:00-05:00</published><updated>2017-07-01T00:00:00-05:00</updated><id>https://waseemwaheed.github.io/DataInvestig8or/d3/visualization/2017/07/01/D3js-Explorations-3</id><author><name></name></author><category term="D3" /><category term="Visualization" /><summary type="html">Today work is my own go at arc diagrams replicating a worked example at Matthew Clemens‚Äôs blog post. My code can be found at Github</summary></entry></feed>